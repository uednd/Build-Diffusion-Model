{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcb7529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "依赖自检\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "env_path = project_root / '.env'\n",
    "if env_path.exists():\n",
    "    for line in env_path.read_text().splitlines():\n",
    "        line = line.strip()\n",
    "        if not line or line.startswith('#') or '=' not in line:\n",
    "            continue\n",
    "        key, value = line.split('=', 1)\n",
    "        value = value.strip().strip(\"'\").strip('\\\"')\n",
    "        os.environ.setdefault(key.strip(), value)\n",
    "\n",
    "\n",
    "from diffusion.env import ensure_dependencies\n",
    "\n",
    "ensure_dependencies()\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as f\n",
    "from torchvision import transforms\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca34634",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Device 自检\n",
    "\"\"\"\n",
    "\n",
    "from diffusion.env import select_device\n",
    "\n",
    "device = select_device(torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d70799",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "加载数据集\n",
    "\"\"\"\n",
    "from diffusion.data import create_dataloader\n",
    "from diffusion.hf import login_hf\n",
    "\n",
    "login_hf()\n",
    "\n",
    "dataset = load_dataset('huggan/smithsonian_butterflies_subset', split='train')\n",
    "\n",
    "image_size = 32\n",
    "batch_size = 64\n",
    "\n",
    "# 图像预处理\n",
    "preprocess = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((image_size, image_size)),  # 统一图像大小（宽x高）\n",
    "        transforms.RandomHorizontalFlip(),            # 随机水平翻转图像\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5], [0.5]),           # 归一化到 [-1, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "def transform(examples):\n",
    "    \"\"\"对数据集中的图像进行预处理\"\"\"\n",
    "    images = [preprocess(image.convert(\"RGB\")) for image in examples['image']]\n",
    "    return {'images': images}\n",
    "\n",
    "# 动态函数，获取数据集内容时，对数据集进行转换\n",
    "dataset.set_transform(transform)\n",
    "\n",
    "train_dataloader = create_dataloader(\n",
    "    dataset,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a28dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "可视化图像数据\n",
    "\"\"\"\n",
    "\n",
    "from PIL import Image\n",
    "from diffusion.visualize import show_images\n",
    "\n",
    "xbatch = next(iter(train_dataloader))['images'].to(device)[:8]\n",
    "print(f'批量图像张量形状: {xbatch.shape}')  # torch.Size([8, 3, 32, 32])\n",
    "show_images(xbatch).resize((8 * 64, 64), resample=Image.NEAREST)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86f18f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "为图像添加噪声\n",
    "\"\"\"\n",
    "\n",
    "from diffusers import DDPMScheduler\n",
    "\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000\n",
    ")\n",
    "\n",
    "timesteps = torch.linspace(0, 999, 8).long().to(device)  # 8 个时间步\n",
    "noise = torch.randn_like(xbatch)  # 生成随机噪声\n",
    "noisy_xbatch = noise_scheduler.add_noise(xbatch, noise, timesteps)  # 添加噪声\n",
    "print(f'添加噪声后的图像张量形状: {noisy_xbatch.shape}')  # torch.Size([8, 3, 32, 32])\n",
    "show_images(noisy_xbatch).resize((8 * 64, 64), resample=Image.NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6411fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "创建扩散模型\n",
    "\"\"\"\n",
    "\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=image_size,        # 输入图像的大小（宽和高）\n",
    "    in_channels=3,                 # 输入图像的通道数（RGB 图像为 3）\n",
    "    out_channels=3,                # 输出图像的通道数\n",
    "    layers_per_block=2,            # 每个块中的层 ResNet 层数\n",
    "    block_out_channels=(64, 128, 128, 256),  # 每个块的输出通道数\n",
    "    down_block_types=(             # 下采样块类型\n",
    "        \"DownBlock2D\", \n",
    "        \"DownBlock2D\", \n",
    "        \"AttnDownBlock2D\", \n",
    "        \"AttnDownBlock2D\"\n",
    "    ),\n",
    "    up_block_types=(               # 上采样块类型\n",
    "        \"AttnUpBlock2D\", \n",
    "        \"AttnUpBlock2D\", \n",
    "        \"UpBlock2D\", \n",
    "        \"UpBlock2D\"\n",
    "    )\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8387d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "创建训练循环\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "noise_scheduler = DDPMScheduler(\n",
    "    num_train_timesteps=1000,\n",
    "    beta_schedule=\"squaredcos_cap_v2\"\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "\n",
    "losses = []\n",
    "\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        clean_images = batch['images'].to(device)\n",
    "        # 1. 生成噪声\n",
    "        noise = torch.randn(clean_images.shape).to(clean_images.device)\n",
    "        bsz = clean_images.shape[0]\n",
    "        # 2. 为每张图像随机选择时间步\n",
    "        timesteps = torch.randint(\n",
    "            0,                                   # 最小时间步\n",
    "            noise_scheduler.num_train_timesteps, # 最大时间步\n",
    "            (bsz,),                              # 生成 bsz 个时间步\n",
    "            device=clean_images.device\n",
    "        ).long()\n",
    "        # 3. 根据每个时间步的噪声大小，添加噪声\n",
    "        noisy_images = noise_scheduler.add_noise(\n",
    "            clean_images, \n",
    "            noise, \n",
    "            timesteps\n",
    "        )\n",
    "        # 4. 预测噪声\n",
    "        noise_pred = model(\n",
    "            noisy_images,\n",
    "            timesteps,\n",
    "            return_dict=False\n",
    "        )[0]\n",
    "        # 5. 计算损失\n",
    "        loss = f.mse_loss(noise_pred, noise)\n",
    "        loss.backward(loss)\n",
    "        losses.append(loss.item())\n",
    "        # 6. 优化模型参数\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    # 每 5 个周期打印一次损失\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        loss_last_epoch = sum(losses[-len(train_dataloader):]) / len(train_dataloader)\n",
    "        print(f'Epoch {epoch+1}, Loss: {loss_last_epoch:.4f}')\n",
    "\n",
    "# 绘制损失曲线\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axs[0].plot(losses)\n",
    "axs[1].plot(np.log(losses))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5123e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用模型生成图像\n",
    "\"\"\"\n",
    "\n",
    "from diffusers import DDPMPipeline\n",
    "\n",
    "# 创建图像生成管线\n",
    "image_pipeline = DDPMPipeline(\n",
    "    unet=model,\n",
    "    scheduler=noise_scheduler\n",
    ")\n",
    "\n",
    "# 生成图像\n",
    "pipeline_output = image_pipeline()\n",
    "pipeline_output.images[0].resize((64, 64), resample=Image.NEAREST)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696f2fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "保存模型和管线\n",
    "\"\"\"\n",
    "\n",
    "image_pipeline.save_pretrained(\"../models/generate_butterflies\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_diffusion_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
