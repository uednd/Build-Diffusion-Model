{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6876c26a4d301dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "依赖自检\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "project_root = Path.cwd().parent\n",
    "sys.path.insert(0, str(project_root / 'src'))\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"PYTORCH_MPS_PREFER_METAL\"] = \"1\"\n",
    "\n",
    "from diffusion.env import ensure_dependencies\n",
    "\n",
    "ensure_dependencies()\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from diffusers import UNet2DModel\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# 提升 MPS 上的 matmul 精度/性能\n",
    "torch.set_float32_matmul_precision(\"high\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31117eea030f52ac",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Device 自检\n",
    "\"\"\"\n",
    "\n",
    "from diffusion.env import select_device\n",
    "\n",
    "device = select_device(torch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7383329e98df77",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "数据集测试\n",
    "\"\"\"\n",
    "\n",
    "from diffusion.data import create_dataloader, create_mnist_dataset\n",
    "\n",
    "# 数据集\n",
    "dataset = create_mnist_dataset(\n",
    "    root=\"../data/datasets\",\n",
    "    train=True,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# 为数据集创建数据加载器\n",
    "dataset_loader = create_dataloader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=0,\n",
    "    persistent_workers=False,\n",
    ")\n",
    "\n",
    "# 从加载器中取出第一批数据\n",
    "x, y = next(iter(dataset_loader))\n",
    "print('Input shape:', x.shape)\n",
    "print('Labels :', y)\n",
    "plt.imshow(torchvision.utils.make_grid(x)[0], cmap = 'gray')  # 以单通道取出所有图像，拼接成大图并用灰度显示\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767613de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "添加噪声，并对输出结果进行可视化\n",
    "\"\"\"\n",
    "\n",
    "from diffusion.noise import corrupt\n",
    "\n",
    "# 绘制输入数据\n",
    "fig, axs = plt.subplots(2, 1, figsize=(12, 5))  # 画布行数，画布列数，画布大小。plt.subplots返回两个方法，第一个是画布对象fig，第二个是子图对象axs\n",
    "plt.subplots_adjust(hspace=0.4)  # 扩大子图间距\n",
    "axs[0].set_title('Input Images')\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0], cmap='gray')  # 以单通道取出所有图像，拼接成大图并用灰度显示\n",
    "\n",
    "# 加入噪声\n",
    "amount = torch.linspace(0, 1, x.shape[0])  # 在指定的范围内，生成一组等距离的数字，数量与x的Batch_size相同\n",
    "noised_x = corrupt(x, amount)\n",
    "\n",
    "# 绘制加入噪声后的图像\n",
    "axs[1].set_title('Corrupted Images (--- amount increases --->)')\n",
    "axs[1].imshow(torchvision.utils.make_grid(noised_x)[0], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672bccd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "UNet2DModel 配置\n",
    "\"\"\"\n",
    "\n",
    "unet_config = {\n",
    "    \"sample_size\": 28,  # 输入图像的大小\n",
    "    \"in_channels\": 1,  # 输入图像的通道数\n",
    "    \"out_channels\": 1,  # 输出图像的通道数\n",
    "    \"layers_per_block\": 2,  # 每个块中的层数\n",
    "    \"block_out_channels\": [32, 64, 64],  # 每个块的输出通道数\n",
    "    \"down_block_types\": [\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "        \"AttnDownBlock2D\",\n",
    "    ],\n",
    "    \"up_block_types\": [\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"AttnUpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "num_train_timesteps = 1000\n",
    "net = UNet2DModel(**unet_config).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa746caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "验证输入和输出的形状是否相同，并查看 UNet2DModel 的参数量\n",
    "\"\"\"\n",
    "\n",
    "x = torch.rand(8, 1, 28, 28).to(device)\n",
    "timesteps = torch.zeros(x.shape[0], dtype=torch.long, device=device)\n",
    "y = net(x, timesteps).sample.shape\n",
    "print(y)\n",
    "\n",
    "sum(p.numel() for p in net.parameters())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f233221",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "开始训练模型\n",
    "\"\"\"\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# 数据加载器\n",
    "dataset_loader = DataLoader(\n",
    "                dataset,                   # 要加载的数据对象\n",
    "                batch_size = batch_size,   # 每次迭代加载的样本数量\n",
    "                shuffle=True,              # 打乱数据顺序\n",
    "                num_workers = 0,\n",
    "                persistent_workers = False\n",
    "                )\n",
    "\n",
    "\n",
    "# 运行周期\n",
    "num_epochs = 3\n",
    "\n",
    "# 使用上文创建的 UNet2DModel\n",
    "\n",
    "# 损失函数（均方误差）\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# 优化器，根据损失函数结果调整网络权重\n",
    "optimizer = torch.optim.AdamW(net.parameters(), lr=1e-3)  # 学习率：1e-3\n",
    "\n",
    "\n",
    "# 记录训练损失\n",
    "loss_history = []\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    for x, _ in dataset_loader:\n",
    "        # 加载数据并添加噪声\n",
    "        x = x.to(device)  # 加载数据\n",
    "        noise_amount = torch.rand(x.shape[0], device=device)  # 为每个样本生成一个随机的噪声数量\n",
    "        noisy_x = corrupt(x, noise_amount)  # 向样本中添加噪声\n",
    "\n",
    "        # 预测的噪声结果\n",
    "        timesteps = torch.zeros(x.shape[0], dtype=torch.long, device=device)\n",
    "        predicted_image = net(noisy_x, timesteps).sample\n",
    "\n",
    "        # 计算损失\n",
    "        loss = loss_fn(predicted_image, x)  # 对比预测结果与原始图像\n",
    "\n",
    "        # 反向传播并更新权重\n",
    "        optimizer.zero_grad()  # 清除之前的梯度\n",
    "        loss.backward()        # 反向传播计算新的梯度\n",
    "        optimizer.step()       # 更新权重\n",
    "        loss_history.append(loss.item())\n",
    "\n",
    "    # 输出每个 epoch 的损失均值\n",
    "    avg_loss = sum(loss_history[-len(dataset_loader):]) / len(dataset_loader)\n",
    "    print(f\"Finished epoch {epoch}. Average loss: {avg_loss:05f}\")\n",
    "\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.plot(loss_history)\n",
    "plt.ylim(0, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d385d4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "观察训练结果\n",
    "\"\"\"\n",
    "\n",
    "x, _ = next(iter(dataset_loader))  # 从数据集中取出一批数据\n",
    "x = x[:8]  # 取出前8个样本\n",
    "\n",
    "amount = torch.linspace(0, 1, x.shape[0])  # 生成一组等距离的噪声数量\n",
    "noised_x = corrupt(x, amount)  # 向样本中添加噪声\n",
    "\n",
    "# 得到模型预测结果\n",
    "with torch.no_grad():  # 在评估模式下，不计算梯度\n",
    "    timesteps = (amount.to(device) * (num_train_timesteps - 1)).long()\n",
    "    predicted_image = net(noised_x.to(device), timesteps).sample.cpu()  # 预测结果，将结果移回CPU（NumPy无法绘制GPU数据）\n",
    "\n",
    "# 绘制结果\n",
    "fig, axs = plt.subplots(3, 1, figsize=(12, 7))\n",
    "axs[0].set_title('Input Images')\n",
    "axs[0].imshow(torchvision.utils.make_grid(x)[0].clip(0, 1), cmap='gray')\n",
    "axs[1].set_title('Corrupted Images (--- amount increases --->)')\n",
    "axs[1].imshow(torchvision.utils.make_grid(noised_x)[0].clip(0, 1), cmap='gray')\n",
    "axs[2].set_title('Predicted Output')\n",
    "axs[2].imshow(torchvision.utils.make_grid(predicted_image)[0].clip(0, 1), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a855a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "拆解采样步骤\n",
    "\"\"\"\n",
    "\n",
    "step = 5\n",
    "x = torch.rand(8, 1, 28, 28).to(device)  # 随机初始化一个图像张量\n",
    "step_history = [x.detach().cpu()]  # 每个步骤的图像\n",
    "predicted_output = []  # 每个步骤的预测输出\n",
    "\n",
    "for i in range(step):\n",
    "    with torch.no_grad():\n",
    "        scale = 1 - (i / (step - 1))\n",
    "        timestep = int(scale * (num_train_timesteps - 1))\n",
    "        timesteps = torch.full((x.shape[0],), timestep, dtype=torch.long, device=device)\n",
    "        predicted_image = net(x, timesteps).sample  # 预测结果\n",
    "        predicted_output.append(predicted_image.detach().cpu())  # 记录预测输出\n",
    "\n",
    "        mix_factor = 1/(step - i)  # 朝预测方向移动的步骤\n",
    "        x = x * (1 - mix_factor) + predicted_image * mix_factor  # 更新图像\n",
    "        step_history.append(x.detach().cpu())  # 记录当前步骤的图像\n",
    "\n",
    "# 绘制每个步骤的图像和预测输出\n",
    "fig, axs = plt.subplots(step, 2, figsize=(9, 4), sharex=True)\n",
    "axs[0, 0].set_title('Input Image')\n",
    "axs[0, 1].set_title('Predicted Output')\n",
    "for i in range(step):\n",
    "    axs[i, 0].imshow(torchvision.utils.make_grid(step_history[i])[0].clip(0, 1), cmap='gray')\n",
    "    axs[i, 1].imshow(torchvision.utils.make_grid(predicted_output[i])[0].clip(0, 1), cmap='gray')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build_diffusion_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}